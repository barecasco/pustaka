
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Setup Â· HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 3.6.6">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="what_is_spark.html" />
    
    
    <link rel="prev" href="../" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Resume</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Cover
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2" data-path="setup.html">
            
                <a href="setup.html">
            
                    
                    Setup
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="setup.html">
            
                <a href="setup.html#sparkdown">
            
                    
                    Spark Download
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="setup.html">
            
                <a href="setup.html#sparkwin">
            
                    
                    Install Spark on Windows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="setup.html">
            
                <a href="setup.html#sparkshell">
            
                    
                    Spark Shell
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="setup.html">
            
                <a href="setup.html#sparkjup">
            
                    
                    Using Spark in jupyter
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="setup.html">
            
                <a href="setup.html#sparkalone">
            
                    
                    Standalone Spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="setup.html">
            
                <a href="setup.html#sparkshut">
            
                    
                    Shutdown Spark
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">Contents</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="what_is_spark.html">
            
                <a href="what_is_spark.html">
            
                    
                    What is Spark?
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="spark_history.html">
            
                <a href="spark_history.html">
            
                    
                    History of Spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="components.html">
            
                <a href="components.html">
            
                    
                    The Components
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="components.html">
            
                <a href="components.html#sparkcore">
            
                    
                    Spark Core
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="components.html">
            
                <a href="components.html#clustermanager">
            
                    
                    Cluster Manager
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.3" data-path="components.html">
            
                <a href="components.html#storagelayer">
            
                    
                    Storage Layer
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="rdd_programming.html">
            
                <a href="rdd_programming.html">
            
                    
                    Programming with RDDs
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Setup</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
                                <section class="normal markdown-section">
                                
                                <h1 id="spark-setup">Spark Setup</h1>
<h3 id="sparkdown">Downloading Spark </h3>
<p>Start by downloading a recent precompiled released version of Spark. Visit</p>
<p><a href="http://spark.apache.org/downloads.html" target="_blank">http://spark.apache.org/downloads.html</a></p>
<p>Select the package type of Prebuilt for <a href="../GLOSSARY.html#hadoop" class="glossary-term" title="Is often used to run ad-hoc exploratory queries on a large datasets,
through SQL interfaces such as Pig and Hive.
Ideally, a user would be able to load dataset of interest into memory accross
a number of machines and query it repeatedly. However, with Hadoop, each query incurs significant
latency (tens of seconds) because it runs as separate MapReduce job and reads data from disk.">Hadoop</a> 2.7 and later. If you have an existing <a href="../GLOSSARY.html#hadoop" class="glossary-term" title="Is often used to run ad-hoc exploratory queries on a large datasets,
through SQL interfaces such as Pig and Hive.
Ideally, a user would be able to load dataset of interest into memory accross
a number of machines and query it repeatedly. However, with Hadoop, each query incurs significant
latency (tens of seconds) because it runs as separate MapReduce job and reads data from disk.">Hadoop</a> cluster or HDFS installation, download the matching version. In Windows you can unpack the tar file with 7-zip.</p>
<p><code>bin</code> folder contains executables that can be used to interact with Spark in various ways. <code>examples</code> contains some helpful Spark standalone jobs that you can look at and run to learn about the Spark API.</p>
<h3 id="sparkwin">Install Spark on Windows </h3>
<p>Take heed this <a href="https://bigdata-madesimple.com/guide-to-install-spark-and-use-pyspark-from-jupyter-in-windows/" target="_blank">guide</a>.</p>
<ol>
<li>Install Java</li>
<li>Set root folder location, me myself set it in <code>D:/spark</code>.</li>
<li>Create new folder <code>./hadoop/bin</code>.</li>
<li>Find and download <code>winutils.exe</code> to be put inside <code>./hadoop/bin</code>.</li>
<li>Add new environment variables: <code>SPARK_HOME</code>, <code>HADOOP_HOME</code>, and <code>PYTHONPATH</code> in a temporary one time init batch script:</li>
</ol>
<pre><code>@echo off
echo setting spark_home and hadoop_home environment variables...
set SPARK_HOME=D:\spark\spark-3.0.0-bin-hadoop2.7
set HADOOP_HOME=D:\spark\spark-3.0.0-bin-hadoop2.7\hadoop
set PYTHONPATH=%SPARK_HOME%\python;%SPARK_HOME%\python\lib\py4j-0.10.9-src.zip;
</code></pre><h3 id="sparkshell">Using Spark Shell </h3>
<p>To use the shell, you can go to <code>%SPARK_HOME%\bin</code> and run <code>pyspark</code>.</p>
<p>At a high level, every Spark application consists of a <em>driver program</em> that launches various parallel operations on a cluster. The driver program contains your application&apos;s main function and defines distributed datasets on the cluster, then applies operations to them. In our case, the driver program was he Spark shell itself, and you could just type in the operations you wanted to run.</p>
<p>Driver programs access Spark through a <code>SparkContext</code> object, which represents a connection to a computing cluster.  In the shell, a <code>SparkContext</code> is automatically created for you as the variable called <code>sc</code>. Once you have a <code>SparkContext</code>, you can use it to build RDDs.</p>
<h3 id="sparkjup">Using Spark in Jupyter </h3>
<p><strong>Important</strong>. The correct pyspark to install is the one come along with the Spark itself (inside the <code>bin</code>).</p>
<p>The Python package <code>findspark</code> should be used to run the Spark in notebook environment, though sometime if the environment variables is set up correctly you may not need to use the package. Below is simple example of using Spark in notebook:</p>
<pre><code>import findspark
findspark.init()
import pyspark
import random
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName(&quot;Agra Spark&quot;).getOrCreate()
sc = spark.sparkContext
</code></pre><h3 id="sparkalone">Standalone Spark </h3>
<p>Apart from running interactively, Spark can be linked into standalone applications in Python. The main difference from using it in the shell is that you need to initialize your own <code>SparkContext</code>, like in the notebook. After that, the API is the same.</p>
<p>The process of linking to Spark varies by language. In Python, you simply write applications as Python scripts, but you must run them using the <code>bin/spark-submit</code> script included in Spark. The <code>spark-submit</code> script includes  the spark dependencies for us in Python. This script sets up the environment for Spark&#x2019;s Python API to function. Simply run your script with the line given :</p>
<p><code>bin/spark-submit my_script.py</code></p>
<p>In standalone you must create your own <code>SparkContext</code>, see example below:</p>
<pre><code>from pyspark import SparkConf, SparkContext

conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;AgraApp&quot;)
sc = SparkContext(conf = conf)
</code></pre><p>Upon creating a <code>SparkContext</code>, you passed two parameters:</p>
<ul>
<li>A cluster URL. <code>&quot;local&quot;</code> in the above example means asking Spark to run one <a href="../GLOSSARY.html#thread" class="glossary-term" title="A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler, which is typically a part of the operating system.">thread</a> on the local <a href="../GLOSSARY.html#machine" class="glossary-term" title="A machine consists of a certain number of nodes,
each of which con-sists of a certain number of cores.">machine</a>, without connecting to the cluster. We can add more <a href="../GLOSSARY.html#thread" class="glossary-term" title="A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler, which is typically a part of the operating system.">thread</a> by appending the number of the threads: <code>&quot;local(3)&quot;</code> will use 3 threads in parallel.</li>
<li>An application name, namely <code>&quot;AgraApp&quot;</code>. This will identify your application on the cluster&apos;s manager&apos;s UI if you connect to a cluster.</li>
</ul>
<h3 id="sparkshut">Shutting Down Spark </h3>
<p>To shut down Spark, you can either call the <code>stop()</code> method on your <code>SparkContext</code>, or simply exit the application.</p>

                                
                                </section>
                            
                        </div>
                    </div>
                
            </div>

            
                
                <a href="../" class="navigation navigation-prev " aria-label="Previous page: Cover">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="what_is_spark.html" class="navigation navigation-next " aria-label="Next page: What is Spark?">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Setup","level":"1.2","depth":1,"next":{"title":"What is Spark?","level":"2.1","depth":1,"path":"contents/what_is_spark.md","ref":"contents/what_is_spark.md","articles":[]},"previous":{"title":"Cover","level":"1.1","depth":1,"path":"README.md","ref":"README.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["katex","-lunr","-search"],"pluginsConfig":{"katex":{},"highlight":{},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Lora","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":true},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"contents/setup.md","mtime":"2020-09-20T04:27:57.643Z","type":"markdown"},"gitbook":{"version":"3.6.6","time":"2020-09-21T14:51:56.982Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

